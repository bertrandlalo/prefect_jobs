.. _Guidelines:

==========
Guidelines
==========

As we extend Iguazu with more pipelines, we converge towards well-defined
rules and notation throughout all our tasks, functions or flows, etc.

Separation of concerns
======================

In Iguazu, there are functions, tasks and flows.
Separation of concerns will help us organize our code.

Please read the complete explanation of these :ref:`Key concepts` to understand
their nuances.

Unit of parallelization
=======================

The *preferred* unit of parallelization is the *file*. A common unit of
parallelization will homogenize the structure of our flows.

In general, tasks and flows are designed to work on several files in parallel.

There are some exceptions to this guideline. For example, when one expects a
file so large that it would be more efficient to parallelize over its contents.

Data exchange
=============

Tasks receive and send *reference to files*. A small data exchange footprint
will reduce the amount of data transmission on our cluster.

A reference to a file can be a path (when using local data) or an identifier
(when using remote data through Quetzal). The :py:mod:`iguazu.helpers.files`
module provides abstractions for these objects.

There are some exceptions to this guideline, mostly related to the exceptions
noted in `Unit of parallelization`_.

.. _rule_file_format:

File format
===========

When saving derived data or results, the *preferred* file format to save
dataframe-like data is HDF5. Refer to the :ref:`hdf5` page for more details.

There are exceptions, where dataframes are not the intended result. For example,
when generating a HTML report. For these cases, there are no guidelines yet.

Base tasks and flows
====================

When creating new tasks, prefer extending the :py:class:`iguazu.Task` class.
It helps you adhere to these guidelines and helps you avoid repeating
a lot of boilerplate code that is common to all tasks. There are more details
on :ref:`Creating new tasks`.

When creating new flows, prefer extending the :py:class:`iguazu.Flow` class.
It will automatically register the flow so that it can be used on the
command-line and it helps other users to compose their flows. There are more
details on :ref:`Creating new flows`.

Empty results
=============

An empty result is a file with no contents, with a size of 0 bytes.

This does not apply when a task does not generate a file, an exception noted in
the `Unit of parallelization`_ and `Data exchange`_ rules.

Metadata
========

Every file generated by Iguazu has metadata associated to it.

Quetzal manages this metadata when working on remote datasets, while local
datasets are handled with JSON files. Since Quetzal organizes metadata in
families, the appropriate family name is ``"iguazu"``.

The strict minimum metadata of a file generated by Iguazu must have the following keys:

================ ==================================================== ==================================================
Name             Description                                          Examples
================ ==================================================== ==================================================
``created_by``    | Name of the program that generated this file.      | Always ``"iguazu"``.
---------------- ---------------------------------------------------- --------------------------------------------------
``version``       | Version of program that generated this file, in    | ``"1.0.2"``.
                  | SemVer_ format.
---------------- ---------------------------------------------------- --------------------------------------------------
``task``          | Fully qualified name of the Iguazu task that       | ``iguazu.tasks.foo.BarTask``.
                  | generated this file.
---------------- ---------------------------------------------------- --------------------------------------------------
``task_version``  | Version of the Iguazu task that generated this     | ``"1.0.2"``.
                  | file, in SemVer_ format.
---------------- ---------------------------------------------------- --------------------------------------------------
``parents``       | A list of identifiers representing the files that  | A list with a UUID4 string.
                  | were used to generate this file. If Iguazu did     | ``["00000000-0000-4000-8000-000000000000"]``
                  | not generate this file or this file is not the
                  | derived data of another one, then this field is
                  | ``null``.
---------------- ---------------------------------------------------- --------------------------------------------------
``status``        | Status of the task that generated this file.       | ``"SUCCESS"`` or ``"FAILED"``.
---------------- ---------------------------------------------------- --------------------------------------------------
``problem``       | An object with details on the error that occurred  | See below
                  | during the execution of the task that generated
                  | this file. This object follows a JSON `RFC-7807`_
                  | structure, in particular, `section 3.1`_.
                  | When a file has been generated without
                  | any error, this field can be ``null``.
================ ==================================================== ==================================================

An example metadata entry for a file with id
``00000000-0000-4000-8000-000000000000`` could have the following metadata:

.. code-block:: json

  {
    "base" : {
      "id": "00000000-0000-4000-8000-000000000000",
      "filename": "foo.hdf5",
      "path": "study/p000",
      "size": 1024
    },
    "iguazu": {
      "id": "00000000-0000-4000-8000-000000000000",
      "created_by": "iguazu",
      "version": "1.1.0",
      "task": "iguazu.tasks.preprocess.Remove50Hz",
      "task_version": "0.2.1",
      "parents": ["006747ea-43a9-4578-9843-63964204b072"],
      "status": "FAILED",
      "problem": {
        "title": "Sampling rate must be > 100 Hz",
        "type": "iguazu.core.exceptions.SoftPreconditionFailed",
        "detail": "... a backtrace ..."
      }
    }
  }

Other metadata families
-----------------------

We have designed the following metadata families to organize a set of metadata
keys that are important for an easier definition of datasets in Iguazu and
Quetzal.

standard
^^^^^^^^

The standard family, named ``"standard"`` contains metadata that inform on the
adherence of the file data to our :ref:`signal <signal_specs>`,
:ref:`event <event_specs>` or :ref:`feature <feature_specs>` specifications. It
contains the following keys:

=============== ==================================================== ==================================================
Name            Description                                          Examples
=============== ==================================================== ==================================================
``signals``      | List of HDF5 groups that follow the signal         | ``["/iguazu/signal/ppg/standard", ...]``
                 | standard
--------------- ---------------------------------------------------- --------------------------------------------------
``events``       | List of HDF5 groups that follow the events         | ``["/iguazu/events/standard", ...]``
                 | standard
--------------- ---------------------------------------------------- --------------------------------------------------
``features``     | List of HDF5 groups that follow the feature        | ``["/iguazu/features/ppg/sequence", ...]``
                 | standard
=============== ==================================================== ==================================================

protocol
^^^^^^^^

The protocol family, named ``"protocol"`` contains information on what program
and context was used to acquire the data of the file. It contains the following
keys:

=============== ==================================================== ==================================================
Name            Description                                          Examples
=============== ==================================================== ==================================================
``name``         | Name of the protocol associated with this file.    | ``"vr"``, ``"typeform-vr"``, ``"c4h"``, ...
--------------- ---------------------------------------------------- --------------------------------------------------
``program``      | Name of the computer program used to acquire       | ``"timeflux"``, ``"quack"``, ...
                 | this file
--------------- ---------------------------------------------------- --------------------------------------------------
``version``      | Version of computer program used to acquire        | ``"1.0.2"``
                 | this file, preferably in SemVer_ format.
--------------- ---------------------------------------------------- --------------------------------------------------
``date``         | Date when the data on this file was acquired.      | ``"2019-09-03 16:58:49.438645+00:00"``
=============== ==================================================== ==================================================

flows
^^^^^

The flow family,  named ``"flows"`` contains log-like entries to mark when a
file has been processed by a flow. The keys of this family are flow names.
For example, ``"ppg"``, ``"behavior"``, etc. The values are either
``"SUCCESS"``, ``"IN_PROGRESS"`` or ``"FAILED"`` to inform that the file has
been successfully processed by the key-named flow, when it is in progress or
when the flow failed for that particular file.

An example metadata object on this family would be:

.. code-block:: json

  {
    "flows": {
       "id": "00000000-0000-4000-8000-000000000000",
       "cardiac": "SUCCESS",
       "galvanic": "FAILED",
       "behavior": "IN_PROGRESS"
    }
  }


Failures
========

A task can fail in two ways: a soft or a hard failure.

Soft failures (or graceful failures) refer to situations when the task
encounters a known problem that should can still generate a result. For example,
a filtering task that receives an empty signal could soft fail in this case,
and generate an empty signal as a result.

Soft failures can generate results. They may be `Empty results`_, or a file
with some other default contents.

Hard failures refer to situations that were unexpected for the task. They
should be reported (automatically) and the any task that depends on the results
of the failed task should not be executed. For example, when a task fails to
download the file that it needs to process (because Quetzal is down or the
network connection failed): this is a hard fail; the task should
not generate a false result just because it could not read the input correctly
due to an external problem.

Hard failures do not generate results. Not even `Empty results`_.
Moreover, hard failures should delete any existing results.

Preconditions
=============

Task should verify any precondition prior to doing its work. When a precondition
is not met, it can choose to hard or soft fail. Use preconditions as safeguards
to your task code.

For example, a task that cleans a signal by using a band-pass filter may want
to verify that the input signal does not have holes in the data (this should
probably be handled beforehand). Depending on the case, this could be a hard
or soft fail.

Postconditions
==============

Like preconditions, tasks should verify any postcondition prior to finishing
up their work. When a postcondition is not met, it *must* hard fail: if your
task does meet a postcondition, it is certainly because something went wrong!
Use postconditions as safeguards on your task code. Postconditions can also
help other users: they can be considered as indirect preconditions to other
tasks.

For example, let us say that a task receives a file and generates a report on
JSON format. One post-condition could be that the output conforms to the JSON
standard format. If the format is not valid, it is better to fail early than to
debug a failure on the downstream tasks.

Task caching
============

To-define: what kind of caches are we using? Prefect cache? Our own
metadata-based and content-based cache? (I personally would prefer the former
but it may not meet all of our needs). When should we cache? What is force?

Plots
=====

To define later:

One task one plot? vs One plot per flow.

Task parameters
===============

What goes in the constructor, on the run method, or on the prefect context?

What is changeable by command-line?

Prefect task best practices
===========================

Follow the `prefect task best practices`_. In particular:

* Task attributes must be serializable
* Avoid statefulness: do not rely on changes of member variables in your run method.


.. _SemVer: https://semver.org
.. _`RFC-7807`: https://tools.ietf.org/html/rfc7807
.. _`section 3.1`: https://tools.ietf.org/html/rfc7807#section-3.1
.. _`prefect task best practices`: https://docs.prefect.io/core/tutorials/task-guide.html#avoid-statefulness
